# Scientific Kill Switches: Falsification Criteria

A valid scientific theory must define the conditions under which it fails. If any of the following are observed experimentally, the **Theory of Hybrid Stability** is considered falsified or irrelevant.

---

## Kill Switch 1: The "Better Algorithm" Scenario

**Condition:** If a purely stochastic operator $M$ (AI alone) achieves a lower long-term error accumulation rate than the optimal hybrid $H \circ M$ in open-ended complex tasks.
**Verdict:** **IRRELEVANCE.** If machines scale perfectly without human grounding, Hybrid Cybernetics is unnecessary.

## Kill Switch 2: The "Biological Supercomputer" Scenario

**Condition:** If a Human Operator $H$ performs better in high-flux environments ($\Phi_{in} \gg C_H$) without pre-filtering than with it.
**Verdict:** **FALSIFICATION.** This would violate Axiom 1 (Capacity Limit), suggesting human attention is unbound.

## Kill Switch 3: The "Coupling Penalty"

**Condition:** If the energetic/attentional cost of verifying AI output exceeds the cost of generating the solution from scratch ($\Delta E_{verify} > \Delta E_{generate}$).
**Verdict:** **FAILURE.** The hybrid system provides no thermodynamic advantage.

## Kill Switch 4: The "Variance Explosion"

**Condition:** If the coupling of $H$ and $M$ consistently increases the total variance of the output (Feedback loop of confusion), rather than damping it.
**Verdict:** **INSTABILITY.** The proposed control topology is invalid.
